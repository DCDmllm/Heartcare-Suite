{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import utils.my_ecg_process as ecg\n",
    "from utils.my_tokenizer import Tokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}\")\n",
    "print(f\"PyTorch sees {torch.cuda.device_count()} GPU(s)\")\n",
    "print(f\"Current device index: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 500\n",
    "batch_size = 32\n",
    "seq_length = 500\n",
    "patch_size = 25\n",
    "latent_ratio = 0.5\n",
    "channels = 12\n",
    "codebook_size = 256\n",
    "residual_levels = 2\n",
    "dir = f\"ecg_tokenizer_level_{residual_levels}_code_{codebook_size}_len_{seq_length}_ratio_{latent_ratio}\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = pd.read_csv('data/ptbxl_database.csv', index_col='ecg_id')\n",
    "# X = ecg.load_raw_data(Y, 'data/', sampling_rate, total_length)\n",
    "# np.save(\"data/records500.npy\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/records500.npy\")\n",
    "total_length = int(seq_length * (1 + latent_ratio))\n",
    "start = int((X.shape[2] - total_length)/2)\n",
    "X = X[:, :, start:start+total_length]\n",
    "Y = pd.read_csv('data/ptbxl_database.csv', index_col='ecg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fold = 9\n",
    "test_fold = 10\n",
    "X_train = X[np.where((Y.strat_fold != valid_fold) & (Y.strat_fold != test_fold))]\n",
    "X_valid = X[np.where(Y.strat_fold == valid_fold)]\n",
    "X_test = X[np.where(Y.strat_fold == test_fold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32))\n",
    "valid_dataset = TensorDataset(torch.tensor(X_valid, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_kwargs = {'residual_levels': residual_levels}\n",
    "tokenizer = Tokenizer(\n",
    "    seq_length=seq_length,\n",
    "    patch_size=patch_size,\n",
    "    latent_ratio=latent_ratio,\n",
    "    channels=channels,\n",
    "    codebook_size=codebook_size,\n",
    "    vq_kwargs=vq_kwargs\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(tokenizer.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=f\"runs/{dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(epoch):\n",
    "    x_train = train_dataset[random.randint(0, len(train_dataset) - 1)][0].unsqueeze(0).to(device)\n",
    "    x_valid = valid_dataset[random.randint(0, len(valid_dataset) - 1)][0].unsqueeze(0).to(device)\n",
    "    channel = random.randint(0, channels - 1)\n",
    "    with torch.no_grad():\n",
    "        _, recon_train, pred_train = tokenizer(x_train[:, :, :seq_length], predict = True)\n",
    "        _, recon_valid, pred_valid = tokenizer(x_valid[:, :, :seq_length], predict = True)\n",
    "\n",
    "    def plot(x, recon, pred, i):\n",
    "        title = \"Train Sample Channel {channel+1}\" if i == 1 else \"Valid Sample Channel {channel+1}\"\n",
    "        plt.subplot(1, 2, i)\n",
    "        x = x.cpu().detach().numpy()[0][channel]\n",
    "        recon = recon.cpu().detach().numpy()[0][channel]\n",
    "        pred = pred.cpu().detach().numpy()[0][channel]\n",
    "        \n",
    "        total_length = len(recon) + len(pred)\n",
    "        time_axis = np.arange(total_length)\n",
    "        \n",
    "        plt.plot(time_axis[:len(x)], x[:total_length], \n",
    "                 label=f\"Original Signal\", color='blue', alpha=0.7, linewidth=1.5)\n",
    "        \n",
    "        plt.plot(time_axis[:len(recon)], recon, \n",
    "                 label=f\"Reconstructed Signal\", color='purple', alpha=0.7, linewidth=1.5)\n",
    "        \n",
    "        pred_start = len(recon)\n",
    "        plt.plot(time_axis[pred_start:], pred, \n",
    "                 label=f\"Predicted Signal\", color='red', alpha=0.7, linewidth=1.5)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time Step\")\n",
    "        plt.ylabel(\"ECG Value\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot(x_train, recon_train, pred_train, 1)\n",
    "    plot(x_valid, recon_valid, pred_valid, 2)\n",
    "    plt.draw()\n",
    "    \n",
    "    img = np.array(plt.gcf().canvas.buffer_rgba())\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    writer.add_image(f\"Prediction/epoch_{epoch+1}\", img, epoch)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "start_epoch = 0\n",
    "model_path = f\"tokenizer/{dir}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(model_path):\n",
    "    checkpoint = torch.load(model_path, weights_only=False)\n",
    "    tokenizer.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\"Resuming training from Epoch {start_epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/100]: 100%|██████████| 545/545 [00:37<00:00, 14.58batch/s, total_loss=1.04] \n",
      "Epoch [51/100]: 100%|██████████| 545/545 [00:37<00:00, 14.63batch/s, total_loss=1.15] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):  \n",
    "    with tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", unit=\"batch\", dynamic_ncols=True) as tepoch:\n",
    "        recon_loss = 0\n",
    "        pred_loss = 0\n",
    "        train_loss = 0\n",
    "        for index, batch in enumerate(tepoch):\n",
    "            x = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            r_loss, _, pred_sequence = tokenizer(x[:, :, :seq_length], predict = True)\n",
    "            p_loss = F.mse_loss(pred_sequence, x[:, :, seq_length:seq_length+pred_sequence.shape[2]])\n",
    "            loss = r_loss + p_loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(tokenizer.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            recon_loss += r_loss.detach().item()\n",
    "            pred_loss += p_loss.detach().item()\n",
    "            train_loss += loss.detach().item()\n",
    "            tepoch.set_postfix(total_loss=loss.item())\n",
    "\n",
    "        avg_train_recon_loss = recon_loss / len(train_loader)\n",
    "        avg_train_pred_loss = pred_loss / len(train_loader)\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        tokenizer.eval()\n",
    "        recon_loss = 0\n",
    "        pred_loss = 0\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                x = batch[0].to(device)\n",
    "                r_loss, _, pred_sequence = tokenizer(x[:, :, :seq_length], predict = True)\n",
    "                p_loss = F.mse_loss(pred_sequence, x[:, :, seq_length:seq_length+pred_sequence.shape[2]])\n",
    "                loss = r_loss + p_loss\n",
    "                recon_loss += r_loss.detach().item()\n",
    "                pred_loss += p_loss.detach().item()\n",
    "                valid_loss += loss.detach().item()\n",
    "        \n",
    "        avg_valid_recon_loss = recon_loss / len(valid_loader)\n",
    "        avg_valid_pred_loss = pred_loss / len(valid_loader)\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        \n",
    "        writer.add_scalars('Loss/Total', {'Train': avg_train_loss, 'Valid': avg_valid_loss}, epoch+1)\n",
    "        writer.add_scalars('Loss/Recon', {'Train': avg_train_recon_loss, 'Valid': avg_valid_recon_loss}, epoch+1)\n",
    "        writer.add_scalars('Loss/Pred', {'Train': avg_train_pred_loss, 'Valid': avg_valid_pred_loss}, epoch+1)\n",
    "        plot_signal(epoch)\n",
    "        model = {\n",
    "            'model_state_dict': tokenizer.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(model, f\"tokenizer/{dir}_50.pth\")\n",
    "        tokenizer.train()\n",
    "    scheduler.step()\n",
    "    \n",
    "model = {\n",
    "    'model_state_dict': tokenizer.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}\n",
    "torch.save(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
